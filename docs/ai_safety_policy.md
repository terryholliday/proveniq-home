# MyARK Internal AI Safety Policy

**Version:** 1.0  
**Effective Date:** 2025-05-01  
**Owner:** AI Safety Specialist

## 1. Acceptable Use Principles
All AI components within MyARK (Valuation Engine, Visual Truth, Document Intelligence) must adhere to the following principles:

1.  **Transparency:** Users must be informed when a decision or value is generated by AI.
2.  **Explainability:** Every AI-generated valuation must be accompanied by "Why we think this" factors.
3.  **Human-in-the-Loop:** High-value transactions (> $5,000) or flagged sensitive items require human review before finalization.

## 2. Bias Mitigation
We actively monitor our models for bias against protected groups or cultural categories.

- **Sensitive Categories:** Items with religious, political, or culturally sensitive metadata are flagged for manual review.
- **Valuation Fairness:** We audit valuation outputs across different ownership demographics (where data allows) to ensure no systematic undervaluation.

## 3. Drift Monitoring
To prevent "hallucinations" or market disconnection:

- **Thresholds:** If a valuation deviates > 50% from the category historical baseline, it is flagged as `HIGH_VARIANCE`.
- **Response:** `HIGH_VARIANCE` results show a wider confidence interval to the user and trigger an internal alert.

## 4. Visual Truth Safety
- **Adversarial Testing:** We regularly test the image pipeline against adversarial attacks (e.g., pixel noise, deepfakes).
- **Privacy:** All images are scanned for PII (faces, documents) before public display. Detected PII must be blurred or redacted.

## 5. Review Protocol
Any incident involving AI safety (e.g., user complaint about biased valuation) must be logged in the incident tracker with the tag `AI_SAFETY`.
